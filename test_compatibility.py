#!/usr/bin/env python3
# -*- coding: utf-8
"""
test_compatibility.py - æµ‹è¯•ç”Ÿæˆçš„æ•°æ®åº“æ˜¯å¦ä¸ç°æœ‰appå…¼å®¹

è¿™ä¸ªè„šæœ¬æ¨¡æ‹Ÿç°æœ‰appçš„æŸ¥è¯¢é€»è¾‘ï¼ŒéªŒè¯ç”Ÿæˆçš„æ•°æ®åº“æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œã€‚
"""

import sqlite3
import struct
from pathlib import Path


def test_database_compatibility():
    """æµ‹è¯•æ•°æ®åº“å…¼å®¹æ€§"""
    print("ğŸ” æµ‹è¯•æ•°æ®åº“å…¼å®¹æ€§...")
    
    # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    db_path = "output/stardict_compatible/chinese_dict.db"
    dict_path = "output/stardict_compatible/chinese_dict.dict"
    
    if not Path(db_path).exists():
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return False
    
    if not Path(dict_path).exists():
        print(f"âŒ å­—å…¸æ–‡ä»¶ä¸å­˜åœ¨: {dict_path}")
        return False
    
    try:
        # è¿æ¥æ•°æ®åº“
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æµ‹è¯•1: æ£€æŸ¥è¡¨ç»“æ„
        print("\nğŸ“‹ æµ‹è¯•1: æ£€æŸ¥è¡¨ç»“æ„")
        cursor.execute("PRAGMA table_info(wordIndex)")
        columns = cursor.fetchall()
        
        expected_columns = [
            (0, 'id', 'INTEGER', 0, None, 1),
            (1, 'word', 'VARCHAR(128)', 0, None, 0),
            (2, 'offset', 'INTEGER', 0, None, 0),
            (3, 'length', 'INTEGER', 0, None, 0)
        ]
        
        if len(columns) == len(expected_columns):
            print("âœ… è¡¨ç»“æ„æ­£ç¡®")
        else:
            print(f"âŒ è¡¨ç»“æ„ä¸åŒ¹é…: æœŸæœ›{len(expected_columns)}åˆ—ï¼Œå®é™…{len(columns)}åˆ—")
            return False
        
        # æµ‹è¯•2: æ£€æŸ¥ç´¢å¼•
        print("\nğŸ” æµ‹è¯•2: æ£€æŸ¥ç´¢å¼•")
        cursor.execute("PRAGMA index_list(wordIndex)")
        indexes = cursor.fetchall()
        
        if len(indexes) >= 2:  # è‡³å°‘åº”è¯¥æœ‰wordå’Œoffsetç´¢å¼•
            print("âœ… ç´¢å¼•åˆ›å»ºæ­£ç¡®")
        else:
            print(f"âŒ ç´¢å¼•æ•°é‡ä¸è¶³: {len(indexes)}")
            return False
        
        # æµ‹è¯•3: æŸ¥è¯¢æµ‹è¯•
        print("\nğŸ” æµ‹è¯•3: æŸ¥è¯¢æµ‹è¯•")
        
        # æµ‹è¯•æŸ¥è¯¢ä¸€äº›å¸¸è§è¯è¯­
        test_words = ['ä½ å¥½', 'ä¸­å›½', 'å­¦ä¹ ', 'è®¡ç®—æœº', 'äººå·¥æ™ºèƒ½']
        
        for word in test_words:
            cursor.execute("SELECT word, offset, length FROM wordIndex WHERE word = ?", (word.lower(),))
            result = cursor.fetchone()
            
            if result:
                print(f"âœ… æ‰¾åˆ°è¯è¯­: {result[0]} (åç§»é‡: {result[1]}, é•¿åº¦: {result[2]})")
                
                # æµ‹è¯•è¯»å–å­—å…¸å†…å®¹
                try:
                    with open(dict_path, 'rb') as f:
                        f.seek(result[1])
                        content = f.read(result[2]).decode('utf-8')
                        if content.startswith('<h2>') and '</h2>' in content:
                            print(f"   ğŸ“– å†…å®¹è¯»å–æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                        else:
                            print(f"   âš ï¸  å†…å®¹æ ¼å¼å¯èƒ½æœ‰é—®é¢˜")
                except Exception as e:
                    print(f"   âŒ è¯»å–å†…å®¹å¤±è´¥: {e}")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°è¯è¯­: {word}")
        
        # æµ‹è¯•4: æ€§èƒ½æµ‹è¯•
        print("\nâš¡ æµ‹è¯•4: æ€§èƒ½æµ‹è¯•")
        
        # æµ‹è¯•éšæœºæŸ¥è¯¢æ€§èƒ½
        import time
        start_time = time.time()
        
        cursor.execute("SELECT COUNT(*) FROM wordIndex")
        total_words = cursor.fetchone()[0]
        
        # éšæœºæŸ¥è¯¢100ä¸ªè¯è¯­
        cursor.execute("SELECT word FROM wordIndex ORDER BY RANDOM() LIMIT 100")
        random_words = cursor.fetchall()
        
        query_count = 0
        for (word,) in random_words:
            cursor.execute("SELECT offset, length FROM wordIndex WHERE word = ?", (word,))
            result = cursor.fetchone()
            if result:
                query_count += 1
        
        end_time = time.time()
        query_time = end_time - start_time
        
        print(f"âœ… éšæœºæŸ¥è¯¢100ä¸ªè¯è¯­ï¼ŒæˆåŠŸ: {query_count}/100ï¼Œè€—æ—¶: {query_time:.3f}ç§’")
        print(f"   å¹³å‡æŸ¥è¯¢æ—¶é—´: {query_time/100*1000:.2f}æ¯«ç§’")
        
        # æµ‹è¯•5: ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æµ‹è¯•5: ç»Ÿè®¡ä¿¡æ¯")
        
        cursor.execute("SELECT COUNT(*) FROM wordIndex")
        total_words = cursor.fetchone()[0]
        
        cursor.execute("SELECT MIN(length), MAX(length), AVG(length) FROM wordIndex")
        min_len, max_len, avg_len = cursor.fetchone()
        
        print(f"   æ€»è¯è¯­æ•°: {total_words}")
        print(f"   å†…å®¹é•¿åº¦èŒƒå›´: {min_len} - {max_len} å­—èŠ‚")
        print(f"   å¹³å‡å†…å®¹é•¿åº¦: {avg_len:.1f} å­—èŠ‚")
        
        conn.close()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åº“ä¸ç°æœ‰appå®Œå…¨å…¼å®¹ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_stardict_format():
    """æµ‹è¯•StarDictæ ¼å¼æ–‡ä»¶"""
    print("\nğŸ” æµ‹è¯•StarDictæ ¼å¼æ–‡ä»¶...")
    
    # æ£€æŸ¥.ifoæ–‡ä»¶
    ifo_path = "output/stardict_compatible/chinese_dict.ifo"
    if Path(ifo_path).exists():
        with open(ifo_path, 'r', encoding='utf-8') as f:
            ifo_content = f.read()
        
        required_fields = ['version', 'bookname', 'wordcount', 'idxfilesize', 'sametypesequence']
        missing_fields = [field for field in required_fields if field not in ifo_content]
        
        if not missing_fields:
            print("âœ… .ifoæ–‡ä»¶æ ¼å¼æ­£ç¡®")
        else:
            print(f"âŒ .ifoæ–‡ä»¶ç¼ºå°‘å­—æ®µ: {missing_fields}")
            return False
    else:
        print("âŒ .ifoæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥.idxæ–‡ä»¶
    idx_path = "output/stardict_compatible/chinese_dict.idx"
    if Path(idx_path).exists():
        idx_size = Path(idx_path).stat().st_size
        print(f"âœ… .idxæ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {idx_size / 1024:.1f} KB")
    else:
        print("âŒ .idxæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥.dictæ–‡ä»¶
    dict_path = "output/stardict_compatible/chinese_dict.dict"
    if Path(dict_path).exists():
        dict_size = Path(dict_path).stat().st_size
        print(f"âœ… .dictæ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {dict_size / 1024 / 1024:.1f} MB")
    else:
        print("âŒ .dictæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ç”Ÿæˆçš„æ•°æ®åº“å…¼å®¹æ€§")
    print("=" * 50)
    
    # æµ‹è¯•æ•°æ®åº“å…¼å®¹æ€§
    db_ok = test_database_compatibility()
    
    # æµ‹è¯•StarDictæ ¼å¼
    stardict_ok = test_stardict_format()
    
    print("\n" + "=" * 50)
    if db_ok and stardict_ok:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nâœ… ç°åœ¨æ‚¨å¯ä»¥å°†ç”Ÿæˆçš„æ–‡ä»¶ç”¨äºç°æœ‰çš„appäº†ï¼š")
        print("   1. å°† chinese_dict.db æ›¿æ¢ç°æœ‰çš„æ•°æ®åº“æ–‡ä»¶")
        print("   2. ä½¿ç”¨ chinese_dict.dict, chinese_dict.idx, chinese_dict.ifo ä½œä¸ºStarDictæ–‡ä»¶")
        print("\nğŸ“± æ‚¨çš„appåº”è¯¥èƒ½å¤Ÿæ­£å¸¸æŸ¥è¯¢è¿™äº›æ•°æ®äº†ï¼")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜")
        return False
    
    return True


if __name__ == '__main__':
    main()

